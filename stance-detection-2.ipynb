{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11413729,"sourceType":"datasetVersion","datasetId":6934041}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-15T08:34:13.291776Z","iopub.execute_input":"2025-04-15T08:34:13.292588Z","iopub.status.idle":"2025-04-15T08:34:37.900948Z","shell.execute_reply.started":"2025-04-15T08:34:13.292560Z","shell.execute_reply":"2025-04-15T08:34:37.900127Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/2024-us-presidential-elections-twitter-data/preprocessedtranslated_tweets_us24.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T08:31:56.123408Z","iopub.execute_input":"2025-04-15T08:31:56.123802Z","iopub.status.idle":"2025-04-15T08:31:56.522276Z","shell.execute_reply.started":"2025-04-15T08:31:56.123777Z","shell.execute_reply":"2025-04-15T08:31:56.521530Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_name = \"declare-lab/flan-alpaca-large\"\n\n# Initialize the tokenizer and model.\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n# Set up the text generation pipeline for text-to-text generation.\ngenerator = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T08:34:44.047145Z","iopub.execute_input":"2025-04-15T08:34:44.047778Z","iopub.status.idle":"2025-04-15T08:34:57.846922Z","shell.execute_reply.started":"2025-04-15T08:34:44.047749Z","shell.execute_reply":"2025-04-15T08:34:57.845795Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create prompts in advance\ndef create_prompt(text):\n    return (\n        \"Classify the tweet's stance towards Democrats in one of the following categories: \"\n        \"Pro Democrat, Anti Democrat, or Neutral.\\n\\n\"\n        f\"Tweet: \\\"{text}\\\"\\n\\n\"\n        \"Answer with only one of the above labels:\"\n    )\n\ndf[\"Prompt\"] = df[\"Text\"].apply(create_prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T08:37:09.669994Z","iopub.execute_input":"2025-04-15T08:37:09.670289Z","iopub.status.idle":"2025-04-15T08:37:09.690055Z","shell.execute_reply.started":"2025-04-15T08:37:09.670266Z","shell.execute_reply":"2025-04-15T08:37:09.689258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 32\nstances = []\n\nfor i in tqdm(range(0, len(df), batch_size), desc=\"Classifying in Batches\"):\n    batch_prompts = df[\"Prompt\"].iloc[i:i + batch_size].tolist()\n    outputs = generator(batch_prompts, max_length=64, do_sample=False, num_return_sequences=1)\n    \n    for out in outputs:\n        # Take only the first word as label, clean and standardize it\n        label = out[\"generated_text\"].strip().split()[0]\n        stances.append(label)\n\n# Add stance column\ndf = df.iloc[:len(stances)]\ndf[\"Stance\"] = stances","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T08:40:39.604307Z","iopub.execute_input":"2025-04-15T08:40:39.604663Z","iopub.status.idle":"2025-04-15T09:47:39.455313Z","shell.execute_reply.started":"2025-04-15T08:40:39.604640Z","shell.execute_reply":"2025-04-15T09:47:39.454572Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save results\ndf.to_csv(\"withStance.csv\", index=False)\nprint(df[[\"Text\", \"Stance\"]].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T09:50:29.036381Z","iopub.execute_input":"2025-04-15T09:50:29.037023Z","iopub.status.idle":"2025-04-15T09:50:29.542180Z","shell.execute_reply.started":"2025-04-15T09:50:29.036998Z","shell.execute_reply":"2025-04-15T09:50:29.541416Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Different Method","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom itertools import chain\nfrom tqdm.auto import tqdm\nfrom transformers import pipeline\nfrom datasets import Dataset  # HuggingFace dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:35:11.828375Z","iopub.execute_input":"2025-04-15T17:35:11.829171Z","iopub.status.idle":"2025-04-15T17:35:12.657571Z","shell.execute_reply.started":"2025-04-15T17:35:11.829144Z","shell.execute_reply":"2025-04-15T17:35:12.656767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tqdm.pandas()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:35:19.596995Z","iopub.execute_input":"2025-04-15T17:35:19.598212Z","iopub.status.idle":"2025-04-15T17:35:19.602768Z","shell.execute_reply.started":"2025-04-15T17:35:19.598185Z","shell.execute_reply":"2025-04-15T17:35:19.601963Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/2024-us-presidential-elections-twitter-data/preprocessedtranslated_tweets_us24.csv')\n\n# 2) Initialize a sentiment-analysis pipeline\nsentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:30:51.427204Z","iopub.execute_input":"2025-04-15T17:30:51.427901Z","iopub.status.idle":"2025-04-15T17:30:55.705885Z","shell.execute_reply.started":"2025-04-15T17:30:51.427869Z","shell.execute_reply":"2025-04-15T17:30:55.705243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_aliases(person):\n    first, last = person[\"first\"], person[\"last\"]\n    full = f\"{first} {last}\"\n    aliases = [full, first, last]\n    if \"nicknames\" in person:\n        aliases.extend(person[\"nicknames\"])\n    if \"handle\" in person:\n        aliases.extend([person[\"handle\"], f\"@{person['handle']}\"])\n    return aliases\n\n# People and slogans\ndem_people = [\n    {\"first\": \"Joe\", \"last\": \"Biden\", \"nicknames\": [\"JoeBiden\"], \"handle\": \"JoeBiden\"},\n    {\"first\": \"Kamala\", \"last\": \"Harris\", \"nicknames\": [\"KamalaHarris\"], \"handle\": \"KamalaHarris\"},\n]\nrep_people = [\n    {\"first\": \"Donald\", \"last\": \"Trump\", \"nicknames\": [\"Trump\"], \"handle\": \"realDonaldTrump\"},\n    {\"first\": \"Nikki\", \"last\": \"Haley\", \"nicknames\": [\"NikkiHaley\"], \"handle\": \"NikkiHaley\"},\n    {\"first\": \"Mike\", \"last\": \"Pence\", \"nicknames\": [\"Pence\"], \"handle\": \"Mike_Pence\"},\n    {\"first\": \"Vivek\", \"last\": \"Ramaswamy\", \"nicknames\": [\"Vivek2024\"], \"handle\": \"VivekGRamaswamy\"},\n    {\"first\": \"JD\", \"last\": \"Vance\", \"nicknames\": [\"JDVance\"], \"handle\": \"JDVance1\"},\n    {\"first\": \"Robert\", \"last\": \"Kennedy Jr.\", \"nicknames\": [\"RFKJr\", \"Kennedy2024\"], \"handle\": \"RobertKennedyJr\"},\n]\n\n# Entities\ndem_entities = list(chain.from_iterable(generate_aliases(p) for p in dem_people)) + [\n    \"democrat\", \"democrats\", \"Democrats\", \"democratic party\", \"dnc\", \"vote blue\", \"blue wave\", \"bidenomics\"\n]\nrep_entities = list(chain.from_iterable(generate_aliases(p) for p in rep_people)) + [\n    \"republican\", \"Republican\", \"republicans\", \"gop\", \"rnc\", \"maga\", \"trump2024\", \"drain the swamp\"\n]\n\n# Regex patterns\ndef compile_pattern(entities):\n    sorted_ents = sorted(set(entities), key=len, reverse=True)\n    pat = r'\\b(' + '|'.join(re.escape(ent) for ent in sorted_ents) + r')\\b'\n    return re.compile(pat, flags=re.IGNORECASE)\n\ndem_pattern = compile_pattern(dem_entities)\nrep_pattern = compile_pattern(rep_entities)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:35:38.653480Z","iopub.execute_input":"2025-04-15T17:35:38.654221Z","iopub.status.idle":"2025-04-15T17:35:38.661890Z","shell.execute_reply.started":"2025-04-15T17:35:38.654197Z","shell.execute_reply":"2025-04-15T17:35:38.661188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def truncate_sent(text, max_len=512):\n    if not isinstance(text, str):\n        return \"\"  # or return a placeholder like \"[no text]\"\n    return text if len(text) <= max_len else text[:max_len]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:40:08.698918Z","iopub.execute_input":"2025-04-15T17:40:08.699656Z","iopub.status.idle":"2025-04-15T17:40:08.703614Z","shell.execute_reply.started":"2025-04-15T17:40:08.699630Z","shell.execute_reply":"2025-04-15T17:40:08.702889Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/2024-us-presidential-elections-twitter-data/preprocessedtranslated_tweets_us24.csv')\nds = Dataset.from_pandas(df[['Text']])  # Just keep the needed column\n\n# Load sentiment model (batch capable)\nsentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", device=0)  # if GPU available\n\n# Apply sentiment in batch\n# 2. If you worry about superâ€‘long texts, truncate in Python:\n# 2) Apply to all tweets\ntruncated_texts = [truncate_sent(t) for t in ds['Text']]\n\n# 3) Run sentiment analysis in batch\nsentiments = sentiment_analyzer(truncated_texts, batch_size=32)\n\nds = ds.add_column(\"Sentiment\", sentiments)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:40:24.517259Z","iopub.execute_input":"2025-04-15T17:40:24.517969Z","iopub.status.idle":"2025-04-15T17:41:00.467483Z","shell.execute_reply.started":"2025-04-15T17:40:24.517942Z","shell.execute_reply":"2025-04-15T17:41:00.466758Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1) Update infer_stance to return a dict\ndef infer_stance(example, pos_threshold=0.7, neg_threshold=0.7):\n    text = example['Text'] or \"\"  # guard against None\n    # check mentions\n    mentions_dem = bool(dem_pattern.search(text))\n    mentions_rep = bool(rep_pattern.search(text))\n\n    # default\n    stance = \"Neutral\"\n    if mentions_dem or mentions_rep:\n        sent = sentiment_analyzer(text[:512])[0]\n        label, score = sent['label'], sent['score']\n        if mentions_dem:\n            if label == \"POSITIVE\" and score >= pos_threshold:\n                stance = \"Pro Democrat\"\n            elif label == \"NEGATIVE\" and score >= neg_threshold:\n                stance = \"Anti Democrat\"\n        elif mentions_rep:\n            if label == \"POSITIVE\" and score >= pos_threshold:\n                stance = \"Anti Democrat\"\n            elif label == \"NEGATIVE\" and score >= neg_threshold:\n                stance = \"Pro Democrat\"\n\n    return {\"Stance\": stance}\n\n# 2) Map over the dataset to add the new column\nds = ds.map(\n    infer_stance,\n    fn_kwargs={\"pos_threshold\": 0.7, \"neg_threshold\": 0.7},\n    remove_columns=[],     # keep all existing columns\n    desc=\"Inferring stance\"\n)\n\n# 3) Bring it back into your DataFrame\ndf['Stance'] = ds['Stance']\n\n# 4) Inspect\nprint(df['Stance'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:42:04.117939Z","iopub.execute_input":"2025-04-15T17:42:04.118680Z","iopub.status.idle":"2025-04-15T17:43:38.133504Z","shell.execute_reply.started":"2025-04-15T17:42:04.118648Z","shell.execute_reply":"2025-04-15T17:43:38.132775Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Zero Shot ","metadata":{}},{"cell_type":"code","source":"df.to_csv('stance.csv',index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:45:23.444337Z","iopub.execute_input":"2025-04-15T17:45:23.444923Z","iopub.status.idle":"2025-04-15T17:45:23.687012Z","shell.execute_reply.started":"2025-04-15T17:45:23.444899Z","shell.execute_reply":"2025-04-15T17:45:23.686453Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df[df['Text'].str.strip().astype(bool)].reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:56:17.030119Z","iopub.execute_input":"2025-04-15T17:56:17.030444Z","iopub.status.idle":"2025-04-15T17:56:17.049717Z","shell.execute_reply.started":"2025-04-15T17:56:17.030423Z","shell.execute_reply":"2025-04-15T17:56:17.049109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import pipeline\n\nclassifier = pipeline(\n    \"zero-shot-classification\",\n    model=\"facebook/bart-large-mnli\",\n    device=0  # your P100\n)\n\ncandidate_labels = [\"Pro Democrat\", \"Anti Democrat\", \"Neutral\"]\n\n# in batches:\nresults = classifier(\n    df[\"Text\"].tolist(),\n    candidate_labels=candidate_labels,\n    batch_size=32,\n    multi_label=False\n)\n\ndf[\"Stance\"] = [r[\"labels\"][0] for r in results]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:56:27.337756Z","iopub.execute_input":"2025-04-15T17:56:27.338281Z","iopub.status.idle":"2025-04-15T17:56:28.583792Z","shell.execute_reply.started":"2025-04-15T17:56:27.338259Z","shell.execute_reply":"2025-04-15T17:56:28.582954Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 32\nresults = []\ntexts = df['Text'].tolist()\n\nfor i in tqdm(range(0, len(texts), batch_size), desc=\"Zeroâ€‘Shot Batches\"):\n    batch = texts[i : i + batch_size]\n    # call the pipeline on a clean list of strings\n    batch_out = classifier(\n        batch,\n        candidate_labels=candidate_labels,\n        multi_label=False,\n        batch_size=batch_size\n    )\n    results.extend(batch_out)\n\n# Extract the top label for each result\ndf['Stance'] = [r['labels'][0] for r in results]\n\n# Quick check\nprint(df['Stance'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T18:27:48.160749Z","iopub.execute_input":"2025-04-15T18:27:48.161111Z","iopub.status.idle":"2025-04-15T18:27:48.166338Z","shell.execute_reply.started":"2025-04-15T18:27:48.161085Z","shell.execute_reply":"2025-04-15T18:27:48.165295Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T18:28:45.737889Z","iopub.execute_input":"2025-04-15T18:28:45.738633Z","iopub.status.idle":"2025-04-15T18:29:50.847751Z","shell.execute_reply.started":"2025-04-15T18:28:45.738608Z","shell.execute_reply":"2025-04-15T18:29:50.846961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.to_csv('stanceZeroShot.csv',index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T18:13:49.510199Z","iopub.execute_input":"2025-04-15T18:13:49.510482Z","iopub.status.idle":"2025-04-15T18:13:49.755021Z","shell.execute_reply.started":"2025-04-15T18:13:49.510461Z","shell.execute_reply":"2025-04-15T18:13:49.754454Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Using CardiffNLPTwitter","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom itertools import chain\nfrom transformers import pipeline\nfrom tqdm.auto import tqdm\n\n# 1) Load & clean your DataFrame\ndf = pd.read_csv('/kaggle/input/2024-us-presidential-elections-twitter-data/preprocessedtranslated_tweets_us24.csv')\ndf['Text'] = df['Text'].fillna(\"\").astype(str)\ndf = df[df['Text'].str.strip().astype(bool)].reset_index(drop=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T18:17:30.283609Z","iopub.execute_input":"2025-04-15T18:17:30.283879Z","iopub.status.idle":"2025-04-15T18:17:30.413921Z","shell.execute_reply.started":"2025-04-15T18:17:30.283861Z","shell.execute_reply":"2025-04-15T18:17:30.413364Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_aliases(person):\n    first, last = person[\"first\"], person[\"last\"]\n    full = f\"{first} {last}\"\n    aliases = [full, first, last]\n    if \"nicknames\" in person:\n        aliases.extend(person[\"nicknames\"])\n    if \"handle\" in person:\n        aliases.extend([person[\"handle\"], f\"@{person['handle']}\"])\n    return aliases\n\n# People and slogans\ndem_people = [\n    {\"first\": \"Joe\", \"last\": \"Biden\", \"nicknames\": [\"JoeBiden\"], \"handle\": \"JoeBiden\"},\n    {\"first\": \"Kamala\", \"last\": \"Harris\", \"nicknames\": [\"KamalaHarris\"], \"handle\": \"KamalaHarris\"},\n]\nrep_people = [\n    {\"first\": \"Donald\", \"last\": \"Trump\", \"nicknames\": [\"Trump\"], \"handle\": \"realDonaldTrump\"},\n    {\"first\": \"Nikki\", \"last\": \"Haley\", \"nicknames\": [\"NikkiHaley\"], \"handle\": \"NikkiHaley\"},\n    {\"first\": \"Mike\", \"last\": \"Pence\", \"nicknames\": [\"Pence\"], \"handle\": \"Mike_Pence\"},\n    {\"first\": \"Vivek\", \"last\": \"Ramaswamy\", \"nicknames\": [\"Vivek2024\"], \"handle\": \"VivekGRamaswamy\"},\n    {\"first\": \"JD\", \"last\": \"Vance\", \"nicknames\": [\"JDVance\"], \"handle\": \"JDVance1\"},\n    {\"first\": \"Robert\", \"last\": \"Kennedy Jr.\", \"nicknames\": [\"RFKJr\", \"Kennedy2024\"], \"handle\": \"RobertKennedyJr\"},\n]\n\n# Entities\ndem_entities = list(chain.from_iterable(generate_aliases(p) for p in dem_people)) + [\n    \"democrat\", \"democrats\", \"Democrats\", \"democratic party\", \"dnc\", \"vote blue\", \"blue wave\", \"bidenomics\"\n]\nrep_entities = list(chain.from_iterable(generate_aliases(p) for p in rep_people)) + [\n    \"republican\", \"Republican\", \"republicans\", \"gop\", \"rnc\", \"maga\", \"trump2024\", \"drain the swamp\"\n]\n\n# Regex patterns\ndef compile_pattern(entities):\n    sorted_ents = sorted(set(entities), key=len, reverse=True)\n    pat = r'\\b(' + '|'.join(re.escape(ent) for ent in sorted_ents) + r')\\b'\n    return re.compile(pat, flags=re.IGNORECASE)\n\ndem_pattern = compile_pattern(dem_entities)\nrep_pattern = compile_pattern(rep_entities)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T18:24:58.739826Z","iopub.execute_input":"2025-04-15T18:24:58.740102Z","iopub.status.idle":"2025-04-15T18:24:58.748259Z","shell.execute_reply.started":"2025-04-15T18:24:58.740081Z","shell.execute_reply":"2025-04-15T18:24:58.747551Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sentiment_pipe = pipeline(\n    \"sentiment-analysis\",\n    model=\"cardiffnlp/twitter-roberta-base-sentiment\",\n    device=0\n)\n\n# 4) Batch infer + map to stance\nbatch_size = 32\nstances = []\ntexts = df['Text'].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T18:25:00.482333Z","iopub.execute_input":"2025-04-15T18:25:00.482597Z","iopub.status.idle":"2025-04-15T18:25:01.256548Z","shell.execute_reply.started":"2025-04-15T18:25:00.482578Z","shell.execute_reply":"2025-04-15T18:25:01.255951Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1) Update infer_stance to return a dict\ndef infer_stance(example, pos_threshold=0.7, neg_threshold=0.7):\n    text = example['Text'] or \"\"  # guard against None\n    # check mentions\n    mentions_dem = bool(dem_pattern.search(text))\n    mentions_rep = bool(rep_pattern.search(text))\n\n    # default\n    stance = \"Neutral\"\n    if mentions_dem or mentions_rep:\n        sent = sentiment_analyzer(text[:512])[0]\n        label, score = sent['label'], sent['score']\n        if mentions_dem:\n            if label == \"POSITIVE\" and score >= pos_threshold:\n                stance = \"Pro Democrat\"\n            elif label == \"NEGATIVE\" and score >= neg_threshold:\n                stance = \"Anti Democrat\"\n        elif mentions_rep:\n            if label == \"POSITIVE\" and score >= pos_threshold:\n                stance = \"Anti Democrat\"\n            elif label == \"NEGATIVE\" and score >= neg_threshold:\n                stance = \"Pro Democrat\"\n\n    return {\"Stance\": stance}\n\n# 2) Map over the dataset to add the new column\nds = ds.map(\n    infer_stance,\n    fn_kwargs={\"pos_threshold\": 0.7, \"neg_threshold\": 0.7},\n    remove_columns=[],     # keep all existing columns\n    desc=\"Inferring stance\"\n)\n\n# 3) Bring it back into your DataFrame\ndf['Stance'] = ds['Stance']\n\n# 4) Inspect\nprint(df['Stance'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T18:25:02.999063Z","iopub.execute_input":"2025-04-15T18:25:02.999346Z","iopub.status.idle":"2025-04-15T18:26:09.831449Z","shell.execute_reply.started":"2025-04-15T18:25:02.999323Z","shell.execute_reply":"2025-04-15T18:26:09.830833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## In-Shot Learning","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom itertools import chain\nfrom transformers import pipeline\nfrom tqdm.auto import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T09:20:41.036842Z","iopub.execute_input":"2025-04-16T09:20:41.037426Z","iopub.status.idle":"2025-04-16T09:20:41.041475Z","shell.execute_reply.started":"2025-04-16T09:20:41.037402Z","shell.execute_reply":"2025-04-16T09:20:41.040684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T09:12:11.364880Z","iopub.execute_input":"2025-04-16T09:12:11.365424Z","iopub.status.idle":"2025-04-16T09:12:12.171275Z","shell.execute_reply.started":"2025-04-16T09:12:11.365405Z","shell.execute_reply":"2025-04-16T09:12:12.170519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    import pandas as pd\n    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n    \n    # Load dataset\n    df = pd.read_csv(\"/kaggle/input/2024-us-presidential-elections-twitter-data/final_raw.csv\")\n    \n    # Manually curate 3-5 representative examples for each class\n    few_shot_examples = [\n    # Pro Democrat\n    (\"Bidenâ€™s student loan relief is a game changer for millions!\", \"Pro Democrat\"),\n    (\"Finally, some real climate action from the White House.\", \"Pro Democrat\"),\n    (\"Kamala Harris handled that debate like a pro. #Leadership\", \"Pro Democrat\"),\n    (\"The Democrats are really pushing for universal healthcare. About time!\", \"Pro Democrat\"),\n    (\"Thanks to Bidenâ€™s infrastructure bill, roads in my town are finally fixed.\", \"Pro Democrat\"),\n\n    # Anti Democrat\n    (\"Wow, another day, another tax hike. Thanks, Democrats.\", \"Anti Democrat\"),\n    (\"Open borders and inflation â€” the Dems' legacy. #Bidenomics\", \"Anti Democrat\"),\n    (\"I miss the days before Bidenomics ruined everything.\", \"Anti Democrat\"),\n    (\"The left only cares about pronouns and cancel culture.\", \"Anti Democrat\"),\n    (\"Why do Democrats hate energy independence so much?\", \"Anti Democrat\"),\n\n    # Neutral\n    (\"Kamala Harris speaks at Howard University tomorrow.\", \"Neutral\"),\n    (\"Joe Biden is set to meet with tech leaders this afternoon.\", \"Neutral\"),\n    (\"The Democratic primary results will be announced at 8 PM.\", \"Neutral\"),\n    (\"New legislation introduced in Congress today.\", \"Neutral\"),\n    (\"The Senate is expected to vote on the immigration bill soon.\", \"Neutral\"),\n\n    # Sarcasm / complex tone\n    (\"Oh great, another inspiring speech from Biden. Canâ€™t wait.\", \"Anti Democrat\"),\n    (\"Democrats are saving America, one trillion dollar bill at a time.\", \"Anti Democrat\"),\n    (\"Guess who just tweeted about climate change again? Kamala. Yay.\", \"Anti Democrat\"),\n    (\"Because banning gas stoves will totally fix everything. Thanks Dems!\", \"Anti Democrat\"),\n\n    # High sentiment intensity\n    (\"Absolutely love how the Biden admin is prioritizing green energy!\", \"Pro Democrat\"),\n    (\"Sick and tired of Democrats ruining the country!\", \"Anti Democrat\"),\n    (\"So many lies from both parties. Iâ€™m done.\", \"Neutral\"),\n    (\"Democrats are doing amazing work on healthcare reform.\", \"Pro Democrat\"),\n    (\"No comment on the Dems, but Iâ€™ll just say... wow.\", \"Neutral\"),\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T09:12:12.172026Z","iopub.execute_input":"2025-04-16T09:12:12.172467Z","iopub.status.idle":"2025-04-16T09:12:12.416199Z","shell.execute_reply.started":"2025-04-16T09:12:12.172449Z","shell.execute_reply":"2025-04-16T09:12:12.415435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MAX_TOKENS = 512\ndef create_few_shot_prompt_safe(text, examples, tokenizer):\n    prompt = \"Classify the stance towards Democrats in these examples:\\n\"\n    for ex_text, ex_label in examples:\n        example = f\"Tweet: {ex_text}\\nStance: {ex_label}\\n\\n\"\n        # Check if adding this example keeps us within token limit\n        if len(tokenizer(prompt + example + f\"Tweet: {text}\\nStance:\")[\"input_ids\"]) <= MAX_TOKENS:\n            prompt += example\n        else:\n            break\n    prompt += (\n        \"Now classify this new tweet. Only respond with Pro Democrat, Anti Democrat, or Neutral.\\n\"\n        f\"Tweet: {text}\\nStance:\"\n    )\n    return prompt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T09:12:12.418086Z","iopub.execute_input":"2025-04-16T09:12:12.418306Z","iopub.status.idle":"2025-04-16T09:12:12.422996Z","shell.execute_reply.started":"2025-04-16T09:12:12.418289Z","shell.execute_reply":"2025-04-16T09:12:12.422303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T09:12:12.423847Z","iopub.execute_input":"2025-04-16T09:12:12.424143Z","iopub.status.idle":"2025-04-16T09:12:12.438442Z","shell.execute_reply.started":"2025-04-16T09:12:12.424127Z","shell.execute_reply":"2025-04-16T09:12:12.437812Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_name = \"declare-lab/flan-alpaca-large\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n# Generator pipeline (using GPU)\ngenerator = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0)\n\n# Build prompts with truncation\ndf[\"prompt\"] = df[\"Text\"].apply(lambda x: create_few_shot_prompt_safe(x, few_shot_examples, tokenizer))\n\n# Convert to Hugging Face Dataset\nhf_dataset = Dataset.from_pandas(df[[\"prompt\"]])\n\n# Run generation efficiently with tqdm progress bar\noutputs = []\nbatch_size = 16\nfor i in tqdm(range(0, len(hf_dataset), batch_size), desc=\"Classifying Tweets\"):\n    batch_prompts = hf_dataset[\"prompt\"][i:i+batch_size]\n    output = generator(batch_prompts, max_length=15, do_sample=False, num_beams=3, early_stopping=True)\n    outputs.extend([out[\"generated_text\"].strip().split(\"\\n\")[0] for out in output])\n\n# Normalize labels\nlabel_map = {\n    \"pro\": \"Pro Democrat\",\n    \"anti\": \"Anti Democrat\",\n    \"neutral\": \"Neutral\",\n    \"democrat\": \"Pro Democrat\",\n    \"against\": \"Anti Democrat\"\n}\n\ndf[\"stance\"] = (\n    pd.Series(outputs)\n    .str.lower()\n    .replace({v.lower(): k for k, v in label_map.items()}, regex=True)\n    .map(label_map)\n    .fillna(\"Neutral\")\n)\n\n# Save final CSV (optional)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T09:20:44.070253Z","iopub.execute_input":"2025-04-16T09:20:44.070965Z","iopub.status.idle":"2025-04-16T11:10:14.638953Z","shell.execute_reply.started":"2025-04-16T09:20:44.070940Z","shell.execute_reply":"2025-04-16T11:10:14.638065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.to_csv(\"inshot3.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T11:11:18.125892Z","iopub.execute_input":"2025-04-16T11:11:18.126533Z","iopub.status.idle":"2025-04-16T11:11:19.949675Z","shell.execute_reply.started":"2025-04-16T11:11:18.126504Z","shell.execute_reply":"2025-04-16T11:11:19.949107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}